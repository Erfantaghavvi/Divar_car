import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import time
import re
import requests
from selenium.webdriver.chrome.options import Options
from logging_config import HAMRAH_LOG_INTERVAL, Z4CAR_LOG_INTERVAL, log_progress, VERBOSE_LOGGING

# Code from hamrah_mechanic_scraper.py
def scrape_hamrah_mechanic(force_update=False):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª Ø®ÙˆØ¯Ø±Ùˆ Ø§Ø² Ø³Ø§ÛŒØª Ù‡Ù…Ø±Ø§Ù‡ Ù…Ú©Ø§Ù†ÛŒÚ© Ø¨Ø§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø±Ø¹Øª
    
    Args:
        force_update (bool): Ø§Ú¯Ø± True Ø¨Ø§Ø´Ø¯ØŒ Ø¨Ø¯ÙˆÙ† ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø²Ù…Ø§Ù† ÙØ§ÛŒÙ„ØŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
    """
    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ù‚Ø¨Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¬Ø¯Ø¯
    import os
    import time
    
    output_filename_xlsx = "hamrah_mechanic_prices.xlsx"
    if not force_update and os.path.exists(output_filename_xlsx):
        try:
            # Ø¨Ø±Ø±Ø³ÛŒ ØªØ§Ø±ÛŒØ® ÙØ§ÛŒÙ„ - Ø§Ú¯Ø± Ú©Ù…ØªØ± Ø§Ø² 12 Ø³Ø§Ø¹Øª Ø§Ø² Ø§ÛŒØ¬Ø§Ø¯ Ø¢Ù† Ú¯Ø°Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
            file_time = os.path.getmtime(output_filename_xlsx)
            current_time = time.time()
            hours_diff = (current_time - file_time) / 3600
            
            if hours_diff < 12:  # Ø§Ú¯Ø± Ú©Ù…ØªØ± Ø§Ø² 12 Ø³Ø§Ø¹Øª Ú¯Ø°Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
                print(f"ğŸ“Š Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ù‡Ù…Ø±Ø§Ù‡ Ù…Ú©Ø§Ù†ÛŒÚ© Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ù‚Ø¨Ù„ÛŒ ({hours_diff:.1f} Ø³Ø§Ø¹Øª Ù¾ÛŒØ´)")
                df = pd.read_excel(output_filename_xlsx)
                # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ÙØ±Ù…Øª Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
                car_data = []
                for _, row in df.iterrows():
                    car_name = row['Car Name']
                    price = row['Price']
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹Ø¯Ø¯ Ù‚ÛŒÙ…Øª Ø§Ø² Ø±Ø´ØªÙ‡
                    price_number = re.sub(r'[^\d]', '', price)
                    if price_number:
                        price_number = int(price_number)
                    else:
                        price_number = 0
                    
                    car_data.append({
                        'Ù†Ø§Ù… Ø®ÙˆØ¯Ø±Ùˆ': car_name,
                        'Ù‚ÛŒÙ…Øª (ØªÙˆÙ…Ø§Ù†)': price_number
                    })
                
                print(f"âœ… {len(car_data)} Ù‚ÛŒÙ…Øª Ø®ÙˆØ¯Ø±Ùˆ Ø§Ø² Ù‡Ù…Ø±Ø§Ù‡ Ù…Ú©Ø§Ù†ÛŒÚ© Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
                return car_data
            else:
                print(f"âš ï¸ ÙØ§ÛŒÙ„ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ù‡Ù…Ø±Ø§Ù‡ Ù…Ú©Ø§Ù†ÛŒÚ© Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ø³Øª ({hours_diff:.1f} Ø³Ø§Ø¹Øª). Ø¯Ø± Ø­Ø§Ù„ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ...")
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ù‚Ø¨Ù„ÛŒ Ù‡Ù…Ø±Ø§Ù‡ Ù…Ú©Ø§Ù†ÛŒÚ©: {e}")
    elif force_update:
        print("ğŸ”„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ù‡Ù…Ø±Ø§Ù‡ Ù…Ú©Ø§Ù†ÛŒÚ©...")
    
    # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² API Ø¨Ù‡ Ø¬Ø§ÛŒ ÙˆØ¨ Ø§Ø³Ú©Ø±Ù¾ÛŒÙ†Ú¯
    try:
        print("ğŸ” ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ Ø§Ø² API Ù‡Ù…Ø±Ø§Ù‡ Ù…Ú©Ø§Ù†ÛŒÚ©...")
        api_url = "https://www.hamrah-mechanic.com/api/v1/car-price/all"
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json',
            'Referer': 'https://www.hamrah-mechanic.com/carprice/'
        }
        
        response = requests.get(api_url, headers=headers, timeout=30)
        if response.status_code == 200:
            try:
                data = response.json()
                if isinstance(data, list) and len(data) > 10:
                    print(f"âœ… Ø¯Ø±ÛŒØ§ÙØª Ù…ÙˆÙÙ‚ {len(data)} Ù‚ÛŒÙ…Øª Ø®ÙˆØ¯Ø±Ùˆ Ø§Ø² API Ù‡Ù…Ø±Ø§Ù‡ Ù…Ú©Ø§Ù†ÛŒÚ©")
                    car_data = []
                    for item in data:
                        if 'name' in item and 'price' in item:
                            car_name = item['name']
                            # ØªØ¨Ø¯ÛŒÙ„ Ù‚ÛŒÙ…Øª Ø¨Ù‡ Ø¹Ø¯Ø¯
                            price_str = str(item['price'])
                            price_number = re.sub(r'[^\d]', '', price_str)
                            if price_number:
                                price_number = int(price_number)
                            else:
                                price_number = 0
                                
                            car_data.append({
                                'Ù†Ø§Ù… Ø®ÙˆØ¯Ø±Ùˆ': car_name,
                                'Ù‚ÛŒÙ…Øª (ØªÙˆÙ…Ø§Ù†)': price_number
                            })
                    
                    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø¹Ø¯ÛŒ
                    df = pd.DataFrame([
                        {"Car Name": item['Ù†Ø§Ù… Ø®ÙˆØ¯Ø±Ùˆ'], "Price": f"{item['Ù‚ÛŒÙ…Øª (ØªÙˆÙ…Ø§Ù†)']:,} ØªÙˆÙ…Ø§Ù†"}
                        for item in car_data
                    ])
                    df.to_excel(output_filename_xlsx, index=False)
                    df.to_csv("hamrah_mechanic_prices.csv", index=False, encoding='utf-8')
                    
                    print(f"âœ… {len(car_data)} Ù‚ÛŒÙ…Øª Ø®ÙˆØ¯Ø±Ùˆ Ø§Ø² Ù‡Ù…Ø±Ø§Ù‡ Ù…Ú©Ø§Ù†ÛŒÚ© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
                    return car_data
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾Ø§Ø³Ø® API: {e}")
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ API: {e}")
    
    # Ø§Ú¯Ø± API Ú©Ø§Ø± Ù†Ú©Ø±Ø¯ØŒ Ø§Ø² ÙˆØ¨ Ø§Ø³Ú©Ø±Ù¾ÛŒÙ†Ú¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
    url = "https://www.hamrah-mechanic.com/carprice/"
    print("ğŸ”§ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ WebDriver Ø¨Ø±Ø§ÛŒ Hamrah Mechanic...")
    
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Chrome Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±
    options = webdriver.ChromeOptions()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-gpu")
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--disable-extensions")
    options.add_argument("--disable-plugins")
    options.add_argument("--disable-images")
    options.add_argument("--disable-javascript")
    options.add_argument("--disable-animations")
    options.add_argument("--disable-web-security")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø¶Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±
    options.add_argument("--disable-background-networking")
    options.add_argument("--disable-background-timer-throttling")
    options.add_argument("--disable-backgrounding-occluded-windows")
    options.add_argument("--disable-breakpad")
    options.add_argument("--disable-component-extensions-with-background-pages")
    options.add_argument("--disable-default-apps")
    options.add_argument("--disable-hang-monitor")
    options.add_argument("--disable-ipc-flooding-protection")
    options.add_argument("--disable-prompt-on-repost")
    options.add_argument("--disable-renderer-backgrounding")
    options.add_argument("--disable-sync")
    options.add_argument("--disable-domain-reliability")
    options.add_argument("--disable-client-side-phishing-detection")
    options.add_argument("--disable-features=UserAgentClientHint")
    options.add_argument("--metrics-recording-only")
    options.add_argument("--no-default-browser-check")
    options.add_argument("--no-first-run")
    options.add_argument("--no-pings")
    
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option('useAutomationExtension', False)
    
    try:
        print("ğŸ“¥ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² webdriver-manager...")
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        print("âœ… WebDriver Ø¨Ø§ webdriver-manager Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯")
    except Exception as e:
        print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± webdriver-manager: {e}")
        print("ğŸ”„ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² chromedriver Ø³ÛŒØ³ØªÙ…...")
        try:
            driver = webdriver.Chrome(options=options)
            print("âœ… WebDriver Ø¨Ø§ chromedriver Ø³ÛŒØ³ØªÙ… Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯")
        except Exception as e2:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ChromeDriver: {e2}")
            raise Exception(f"Unable to locate or obtain driver for chrome: {e2}")
    
    driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
    driver.set_page_load_timeout(20)  # Ú©Ø§Ù‡Ø´ ØªØ§ÛŒÙ…â€ŒØ§ÙˆØª Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±

    print(f"Navigating to {url}...")
    driver.get(url)

    try:
        wait = WebDriverWait(driver, 20)  # Ú©Ø§Ù‡Ø´ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø±
        print("Waiting for page to load...")
        time.sleep(5)  # Ú©Ø§Ù‡Ø´ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø±
        
        # Ø§Ø³Ú©Ø±ÙˆÙ„ Ø³Ø±ÛŒØ¹â€ŒØªØ±
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight/2);")
        time.sleep(2)
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(2)
        driver.execute_script("window.scrollTo(0, 0);")
        
        car_data = []
        page_source = driver.page_source
        soup = BeautifulSoup(page_source, 'html.parser')
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³Ù„Ú©ØªÙˆØ±Ù‡Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØªØ±
        price_tables = soup.find_all(['table', 'div'], class_=lambda c: c and ('price-table' in c or 'price_table' in c))
        print(f"Found {len(price_tables)} price tables")
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±Ù‡Ø§ Ø¨Ø§ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±
        unique_cars = {}
        
        for table in price_tables:
            try:
                rows = table.find_all(['tr', 'div'], class_=lambda c: c and ('row' in c or 'item' in c))
                for row in rows:
                    try:
                        # Ø¬Ø³ØªØ¬ÙˆÛŒ Ø§Ù†Ø¹Ø·Ø§Ùâ€ŒÙ¾Ø°ÛŒØ±ØªØ± Ø¨Ø±Ø§ÛŒ Ø³Ù„ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù… Ùˆ Ù‚ÛŒÙ…Øª
                        name_cell = row.find(['td', 'div'], class_=lambda c: c and ('right' in c or 'name' in c or 'title' in c))
                        price_cell = row.find(['td', 'div'], class_=lambda c: c and ('left' in c or 'price' in c))
                        
                        if name_cell and price_cell:
                            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ù… Ø®ÙˆØ¯Ø±Ùˆ
                            car_name = name_cell.get_text(strip=True)
                            if not car_name:
                                car_name_div = name_cell.find(['div', 'span'], class_=lambda c: c and ('name' in c or 'title' in c))
                                if car_name_div:
                                    car_name = car_name_div.get_text(strip=True)
                            
                            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª
                            price_text = price_cell.get_text(strip=True)
                            if not price_text or not re.search(r'\d', price_text):
                                price_div = price_cell.find(['div', 'span'], class_=lambda c: c and ('price' in c or 'number' in c))
                                if price_div:
                                    price_text = price_div.get_text(strip=True)
                            
                            if car_name and price_text and re.search(r'\d', price_text):
                                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹Ø¯Ø¯ Ù‚ÛŒÙ…Øª
                                price_number = re.sub(r'[^\d]', '', price_text)
                                if price_number:
                                    price_number = int(price_number)
                                    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±Ù‡Ø§
                                    unique_cars[car_name] = price_number
                    except Exception as e:
                        continue
            except Exception as e:
                continue
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ù‡ Ù„ÛŒØ³Øª Ù†Ù‡Ø§ÛŒÛŒ
        car_data = [
            {'Ù†Ø§Ù… Ø®ÙˆØ¯Ø±Ùˆ': name, 'Ù‚ÛŒÙ…Øª (ØªÙˆÙ…Ø§Ù†)': price}
            for name, price in unique_cars.items()
        ]
        
        print(f"Extracted {len(car_data)} unique car records.")
        
        if car_data:
            # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¨Ø¹Ø¯ÛŒ
            df = pd.DataFrame([
                {"Car Name": item['Ù†Ø§Ù… Ø®ÙˆØ¯Ø±Ùˆ'], "Price": f"{item['Ù‚ÛŒÙ…Øª (ØªÙˆÙ…Ø§Ù†)']:,} ØªÙˆÙ…Ø§Ù†"}
                for item in car_data
            ])
            df.to_excel(output_filename_xlsx, index=False)
            df.to_csv("hamrah_mechanic_prices.csv", index=False, encoding='utf-8')
            
            print(f"âœ… {len(car_data)} Ù‚ÛŒÙ…Øª Ø®ÙˆØ¯Ø±Ùˆ Ø§Ø² Ù‡Ù…Ø±Ø§Ù‡ Ù…Ú©Ø§Ù†ÛŒÚ© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
        else:
            print("No data was extracted.")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ù‡Ù…Ø±Ø§Ù‡ Ù…Ú©Ø§Ù†ÛŒÚ©: {e}")
        car_data = []
    finally:
        print("Closing the WebDriver.")
        driver.quit()
    
    return car_data

# Code from z4car_scraper.py
class Z4CarScraper:
    def __init__(self):
        self.base_url = "https://z4car.com"
        self.price_url = "https://z4car.com/price"
        self.driver = None
    
    def setup_driver(self):
        try:
            print("ğŸ”§ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ WebDriver Ø¨Ø±Ø§ÛŒ Z4Car...")
            
            # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Chrome Ø¨Ù‡ÛŒÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±
            chrome_options = Options()
            chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_argument('--disable-extensions')
            chrome_options.add_argument('--disable-plugins')
            chrome_options.add_argument('--disable-images')
            chrome_options.add_argument('--disable-javascript')
            chrome_options.add_argument('--disable-animations')
            chrome_options.add_argument('--disable-web-security')
            chrome_options.add_argument('--window-size=1920,1080')
            chrome_options.add_argument('--user-agent=Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
            
            # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø¶Ø§ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±
            chrome_options.add_argument("--disable-background-networking")
            chrome_options.add_argument("--disable-background-timer-throttling")
            chrome_options.add_argument("--disable-backgrounding-occluded-windows")
            chrome_options.add_argument("--disable-breakpad")
            chrome_options.add_argument("--disable-component-extensions-with-background-pages")
            chrome_options.add_argument("--disable-default-apps")
            chrome_options.add_argument("--disable-hang-monitor")
            chrome_options.add_argument("--disable-ipc-flooding-protection")
            chrome_options.add_argument("--disable-prompt-on-repost")
            chrome_options.add_argument("--disable-renderer-backgrounding")
            chrome_options.add_argument("--disable-sync")
            chrome_options.add_argument("--disable-domain-reliability")
            chrome_options.add_argument("--disable-client-side-phishing-detection")
            chrome_options.add_argument("--disable-features=UserAgentClientHint")
            chrome_options.add_argument("--metrics-recording-only")
            chrome_options.add_argument("--no-default-browser-check")
            chrome_options.add_argument("--no-first-run")
            chrome_options.add_argument("--no-pings")
            
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            
            try:
                print("ğŸ“¥ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² webdriver-manager...")
                service = Service(ChromeDriverManager().install())
                self.driver = webdriver.Chrome(service=service, options=chrome_options)
                print("âœ… WebDriver Ø¨Ø§ webdriver-manager Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯")
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± webdriver-manager: {e}")
                print("ğŸ”„ ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² chromedriver Ø³ÛŒØ³ØªÙ…...")
                try:
                    self.driver = webdriver.Chrome(options=chrome_options)
                    print("âœ… WebDriver Ø¨Ø§ chromedriver Ø³ÛŒØ³ØªÙ… Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø´Ø¯")
                except Exception as e2:
                    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ ChromeDriver: {e2}")
                    raise Exception(f"Unable to locate or obtain driver for chrome: {e2}")
            
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            self.driver.set_page_load_timeout(20)  # Ú©Ø§Ù‡Ø´ ØªØ§ÛŒÙ…â€ŒØ§ÙˆØª Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±
            return True
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ WebDriver: {e}")
            return False
    
    def get_page_content(self, url):
        try:
            print(f"à¸šà¸²à¸£à¸¢Ø°Ø§Ø±ÛŒ ØµÙØ­Ù‡: {url}")
            self.driver.get(url)
            WebDriverWait(self.driver, 10).until(EC.presence_of_element_located((By.TAG_NAME, "body")))
            time.sleep(2)
            # Ø§Ø³Ú©Ø±ÙˆÙ„ Ø³Ø±ÛŒØ¹â€ŒØªØ± Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø±Ø¹Øª
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight/2);")
            time.sleep(1)
            self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1)
            return self.driver.page_source
        except Exception as e:
            print(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡: {e}")
            # ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³Ø§Ø¯Ù‡â€ŒØªØ±
            try:
                print("ğŸ”„ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¨Ø§ Ø²Ù…Ø§Ù† Ø§Ù†ØªØ¸Ø§Ø± Ú©Ù…ØªØ±...")
                self.driver.get(url)
                time.sleep(3)
                return self.driver.page_source
            except Exception as e2:
                print(f"Ø®Ø·Ø§ Ø¯Ø± ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯: {e2}")
                return None
    
    def clean_price(self, price_text):
        if not price_text:
            return None
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ú©Ø´ Ø¨Ø±Ø§ÛŒ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ
        if not hasattr(self, '_price_cache'):
            self._price_cache = {}
        
        if price_text in self._price_cache:
            return self._price_cache[price_text]
            
        price_matches = re.findall(r'\d{1,3}(?:,\d{3})+', price_text)
        if price_matches:
            for price_match in price_matches:
                clean_price_text = price_match.replace(',', '')
                try:
                    price_value = int(clean_price_text)
                    if price_value > 10000000:
                        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ú©Ø´
                        self._price_cache[price_text] = price_value
                        return price_value
                except:
                    continue
        return None
    
    def extract_individual_prices(self, price_text):
        if not price_text:
            return []
        price_matches = re.findall(r'\d{1,3}(?:,\d{3})+', price_text)
        valid_prices = []
        for price_match in price_matches:
            clean_price_text = price_match.replace(',', '')
            try:
                price_value = int(clean_price_text)
                if price_value > 10000000:
                    valid_prices.append(price_value)
            except:
                continue
        return valid_prices
    
    def extract_car_prices(self, html_content):
        soup = BeautifulSoup(html_content, 'html.parser')
        cars_data = []
        print("Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¨Ù„ÙˆÚ©â€ŒÙ‡Ø§ÛŒ Ù‚ÛŒÙ…Øª Ø®ÙˆØ¯Ø±Ùˆ...")
        
        # Ø°Ø®ÛŒØ±Ù‡ HTML ÙÙ‚Ø· Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ø¨Ø±Ø§ÛŒ Ø¯ÛŒØ¨Ø§Ú¯
        debug_mode = False
        if debug_mode:
            with open('z4car_debug.html', 'w', encoding='utf-8') as f:
                f.write(html_content)
            print("HTML ØµÙØ­Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ z4car_debug.html Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
        
        # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‡Ù…Ø²Ù…Ø§Ù† Ú†Ù†Ø¯ÛŒÙ† Ú©Ù„Ø§Ø³ Ù…Ø±ØªØ¨Ø· Ø¨Ø§ Ù‚ÛŒÙ…Øª - Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡
        entry_bodies = soup.find_all(['div', 'section'], class_=lambda c: c and ('entry' in c or 'price' in c or 'content' in c or 'car' in c))
        print(f"ÛŒØ§ÙØª Ø´Ø¯ {len(entry_bodies)} Ø¨Ù„ÙˆÚ© Ù…Ø­ØªÙˆØ§")
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±Ù‡Ø§ Ø¨Ø§ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±
        unique_cars = {}
        
        # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±
        for entry in entry_bodies:
            try:
                # Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‡Ù…Ø²Ù…Ø§Ù† Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§ Ùˆ Ø¬Ø¯ÙˆÙ„â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù‡Ø´ Ø²Ù…Ø§Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´
                ul_elements = entry.find_all('ul')
                tables = entry.find_all('table')
                
                # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù„ÛŒØ³Øªâ€ŒÙ‡Ø§
                for ul in ul_elements:
                    li_elements = ul.find_all('li')
                    if len(li_elements) >= 2:  # Ú©Ø§Ù‡Ø´ Ø¨ÛŒØ´ØªØ± Ø­Ø¯Ø§Ù‚Ù„ ØªØ¹Ø¯Ø§Ø¯ Ø¢ÛŒØªÙ…â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ù…ÙˆØ§Ø±Ø¯ Ø¨ÛŒØ´ØªØ±
                        car_info = self.extract_from_columns(li_elements)
                        if car_info:
                            car_name = car_info['Ù†Ø§Ù… Ø®ÙˆØ¯Ø±Ùˆ']
                            price = car_info['Ù‚ÛŒÙ…Øª Ø¹Ø¯Ø¯ÛŒ']
                            if car_name not in unique_cars or price > unique_cars[car_name]['Ù‚ÛŒÙ…Øª Ø¹Ø¯Ø¯ÛŒ']:
                                unique_cars[car_name] = car_info
                                if len(unique_cars) % Z4CAR_LOG_INTERVAL == 0:
                                     log_progress(f"Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯: {car_name} - {car_info['Ù‚ÛŒÙ…Øª (ØªÙˆÙ…Ø§Ù†)']}")
                
                # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¬Ø¯ÙˆÙ„â€ŒÙ‡Ø§ Ø¨Ø§ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØªØ±
                for table in tables:
                    rows = table.find_all('tr')
                    for row in rows:
                        cells = row.find_all(['td', 'th'])
                        if len(cells) >= 2:
                            car_name = cells[0].get_text(strip=True)
                            # Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ù…Ù‡ Ø³Ù„ÙˆÙ„â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù‚ÛŒÙ…Ø§Ù†Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ ÛŒØ§ÙØªÙ† Ù‚ÛŒÙ…Øª
                            for cell in cells[1:]:
                                price_text = cell.get_text(strip=True)
                                if car_name and price_text and re.search(r'\d', price_text):
                                    price = self.clean_price(price_text)
                                    if price and price > 100000:
                                        car_info = {
                                            'Ù†Ø§Ù… Ø®ÙˆØ¯Ø±Ùˆ': car_name.strip(),
                                            'ÙˆØ¶Ø¹ÛŒØª': 'Ù†Ø§Ù…Ø´Ø®Øµ',
                                            'Ø³Ø§Ù„': 'Ù†Ø§Ù…Ø´Ø®Øµ',
                                            'Ù‚ÛŒÙ…Øª (ØªÙˆÙ…Ø§Ù†)': f"{price:,}",
                                            'Ù‚ÛŒÙ…Øª Ø¹Ø¯Ø¯ÛŒ': price
                                        }
                                        if car_name not in unique_cars or price > unique_cars[car_name]['Ù‚ÛŒÙ…Øª Ø¹Ø¯Ø¯ÛŒ']:
                                            unique_cars[car_name] = car_info
                                            break  # Ù¾Ø³ Ø§Ø² ÛŒØ§ÙØªÙ† Ø§ÙˆÙ„ÛŒÙ† Ù‚ÛŒÙ…Øª Ù…Ø¹ØªØ¨Ø±ØŒ Ø¨Ù‡ Ø³Ø±Ø§Øº Ø±Ø¯ÛŒÙ Ø¨Ø¹Ø¯ÛŒ Ø¨Ø±Ùˆ
            except Exception as e:
                continue
        
        # Ø§Ú¯Ø± Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ØŒ Ø§Ø² Ø±ÙˆØ´ Ø¹Ù…ÙˆÙ…ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
        if not unique_cars:
            print("Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´ Ø¹Ù…ÙˆÙ…ÛŒ...")
            general_cars = self.extract_general_method(soup)
            for car in general_cars:
                car_name = car['Ù†Ø§Ù… Ø®ÙˆØ¯Ø±Ùˆ']
                price = car['Ù‚ÛŒÙ…Øª Ø¹Ø¯Ø¯ÛŒ']
                if car_name not in unique_cars or price > unique_cars[car_name]['Ù‚ÛŒÙ…Øª Ø¹Ø¯Ø¯ÛŒ']:
                    unique_cars[car_name] = car
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ù‡ Ù„ÛŒØ³Øª
        cars_data = list(unique_cars.values())
        return cars_data
    
    def extract_from_columns(self, li_elements):
        try:
            car_name = "Ù†Ø§Ù…Ø´Ø®Øµ"
            condition = "Ù†Ø§Ù…Ø´Ø®Øµ"
            year = "Ù†Ø§Ù…Ø´Ø®Øµ"
            price_text = "Ù†Ø§Ù…Ø´Ø®Øµ"
            for i, li in enumerate(li_elements):
                text = li.get_text(strip=True)
                if i == 0:
                    img = li.find('img')
                    if img and img.get('alt'):
                        alt_text = img.get('alt')
                        car_match = re.search(r'(Ø¢Ø¦ÙˆØ¯ÛŒ|Ù¾Ú˜Ùˆ|Ø³Ù…Ù†Ø¯|Ù¾Ø±Ø§ÛŒØ¯|ØªÛŒØ¨Ø§|Ø¯Ù†Ø§|Ø±Ø§Ù†Ø§|Ø³Ø§ÛŒÙ¾Ø§|Ú©ÙˆÛŒÛŒÚ©|Ø¢Ø±ÛŒÙˆ|Ø´Ø§Ù‡ÛŒÙ†|ØªØ§Ø±Ø§|Ø³Ø§ÛŒÙ†Ø§|Ù…Ø²Ø¯Ø§|Ù‡ÙˆÙ†Ø¯Ø§|ØªÙˆÛŒÙˆØªØ§|Ù†ÛŒØ³Ø§Ù†|Ù‡ÛŒÙˆÙ†Ø¯Ø§ÛŒ|Ú©ÛŒØ§|Ú†Ø±ÛŒ|Ø§Ù… ÙˆÛŒ Ø§Ù…|Ø¯ÙˆÙˆ|Ø±Ù†Ùˆ|ÙÙˆÙ„Ú©Ø³|Ø¨ÛŒ Ø§Ù… Ùˆ|Ø¨Ù†Ø²|Ø¢Ù„ÙØ§Ø±ÙˆÙ…Ø¦Ùˆ|Ø¢Ù…ÛŒÚ©Ùˆ)[^\n]*', alt_text, re.I)
                        if car_match:
                            car_name = car_match.group()
                    if car_name == "Ù†Ø§Ù…Ø´Ø®Øµ":
                        car_match = re.search(r'Ù‚ÛŒÙ…Øª\s+([^\n]+)', text, re.I)
                        if car_match:
                            car_name = car_match.group(1)
                if "ØµÙØ±" in text:
                    condition = "ØµÙØ± Ú©ÛŒÙ„ÙˆÙ…ØªØ±"
                elif "Ú©Ø§Ø±Ú©Ø±Ø¯Ù‡" in text:
                    condition = "Ú©Ø§Ø±Ú©Ø±Ø¯Ù‡"
                year_match = re.search(r'(20\d{2}|13\d{2}|14\d{2})', text)
                if year_match:
                    year = year_match.group(1)
                price_match = re.search(r'\d{1,3}(,\d{3})+', text)
                if price_match:
                    price_text = text
            if price_text != "Ù†Ø§Ù…Ø´Ø®Øµ":
                clean_price = self.clean_price(price_text)
                if clean_price and clean_price > 100000:
                    return {
                        'Ù†Ø§Ù… Ø®ÙˆØ¯Ø±Ùˆ': car_name.strip(),
                        'ÙˆØ¶Ø¹ÛŒØª': condition,
                        'Ø³Ø§Ù„': year,
                        'Ù‚ÛŒÙ…Øª (ØªÙˆÙ…Ø§Ù†)': f"{clean_price:,}",
                        'Ù‚ÛŒÙ…Øª Ø¹Ø¯Ø¯ÛŒ': clean_price
                    }
            return None
        except:
            return None
    
    def extract_general_method(self, soup):
        cars_data = []
        # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±Ù‡Ø§ Ø¨Ø§ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±
        unique_cars_dict = {}
        
        # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ: Ø¬Ø³ØªØ¬ÙˆÛŒ Ù‡Ù…Ø²Ù…Ø§Ù† Ú†Ù†Ø¯ÛŒÙ† Ù†ÙˆØ¹ Ø¹Ù†ØµØ± Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±
        price_elements = soup.find_all(['div', 'span', 'p'], class_=re.compile(r'price|car|vehicle', re.I))
        price_elements.extend(soup.find_all(string=re.compile(r'Ù‚ÛŒÙ…Øª', re.I)))
        price_elements.extend(soup.find_all(string=re.compile(r'\d{1,3}(,\d{3})+')))
        print(f"ÛŒØ§ÙØª Ø´Ø¯ {len(price_elements)} Ø¹Ù†ØµØ± Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ")
        print("Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø®ÙˆØ¯Ø±ÙˆÙ‡Ø§ Ø¨Ø§ Ø±ÙˆØ´ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡... (Ù„Ø§Ú¯ Ù‡Ø± 50 Ø±Ú©ÙˆØ±Ø¯)")
        
        # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ: Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±
        for element in price_elements:
            try:
                if isinstance(element, str):
                    text = element
                    parent = None
                else:
                    text = element.get_text(strip=True)
                    parent = element.parent
                individual_prices = self.extract_individual_prices(text)
                if individual_prices:
                    car_name = "Ù†Ø§Ù…Ø´Ø®Øµ"
                    # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ: Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ø¬Ø³ØªØ¬ÙˆÛŒ Ø¨Ù‡ØªØ± Ø¨Ø±Ø§ÛŒ Ù†Ø§Ù… Ø®ÙˆØ¯Ø±Ùˆ
                    car_patterns = [
                        r'Ù‚ÛŒÙ…Øª\s+([^\n]+)',
                        r'(Ø¢Ø¦ÙˆØ¯ÛŒ|Ù¾Ú˜Ùˆ|Ø³Ù…Ù†Ø¯|Ù¾Ø±Ø§ÛŒØ¯|ØªÛŒØ¨Ø§|Ø¯Ù†Ø§|Ø±Ø§Ù†Ø§|Ø³Ø§ÛŒÙ¾Ø§|Ú©ÙˆÛŒÛŒÚ©|Ø¢Ø±ÛŒÙˆ|Ø´Ø§Ù‡ÛŒÙ†|ØªØ§Ø±Ø§|Ø³Ø§ÛŒÙ†Ø§|Ù…Ø²Ø¯Ø§|Ù‡ÙˆÙ†Ø¯Ø§|ØªÙˆÛŒÙˆØªØ§|Ù†ÛŒØ³Ø§Ù†|Ù‡ÛŒÙˆÙ†Ø¯Ø§ÛŒ|Ú©ÛŒØ§|Ú†Ø±ÛŒ|Ø§Ù… ÙˆÛŒ Ø§Ù…|Ø¯ÙˆÙˆ|Ø±Ù†Ùˆ|ÙÙˆÙ„Ú©Ø³|Ø¨ÛŒ Ø§Ù… Ùˆ|Ø¨Ù†Ø²|Ø¢Ù„ÙØ§Ø±ÙˆÙ…Ø¦Ùˆ|Ø¢Ù…ÛŒÚ©Ùˆ)[^\n]*',
                    ]
                    
                    # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ: Ø¬Ø³ØªØ¬ÙˆÛŒ Ø³Ø±ÛŒØ¹â€ŒØªØ± Ø¨Ø§ Ø´Ú©Ø³Øª Ø­Ù„Ù‚Ù‡ Ù¾Ø³ Ø§Ø² ÛŒØ§ÙØªÙ† Ø§ÙˆÙ„ÛŒÙ† ØªØ·Ø§Ø¨Ù‚
                    for pattern in car_patterns:
                        match = re.search(pattern, text, re.I)
                        if match:
                            car_name = match.group(1) if match.lastindex else match.group()
                            break
                    
                    # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ: Ø¨Ø±Ø±Ø³ÛŒ ÙÙ‚Ø· Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø²
                    if car_name == "Ù†Ø§Ù…Ø´Ø®Øµ" and parent:
                        parent_text = parent.get_text(strip=True)
                        for pattern in car_patterns:
                            match = re.search(pattern, parent_text, re.I)
                            if match:
                                car_name = match.group(1) if match.lastindex else match.group()
                                break
                    
                    # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ: Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± Ø®ÙˆØ§Ù‡Ø±/Ø¨Ø±Ø§Ø¯Ø±Ù‡Ø§ Ø¨Ù‡ ÙÙ‚Ø· 3 Ù…ÙˆØ±Ø¯ Ø§ÙˆÙ„
                    if car_name == "Ù†Ø§Ù…Ø´Ø®Øµ" and parent:
                        siblings = parent.find_previous_siblings() + parent.find_next_siblings()
                        for sibling in siblings[:3]:  # ÙÙ‚Ø· 3 Ù…ÙˆØ±Ø¯ Ø§ÙˆÙ„
                            if hasattr(sibling, 'get_text'):
                                sibling_text = sibling.get_text(strip=True)
                                for pattern in car_patterns:
                                    match = re.search(pattern, sibling_text, re.I)
                                    if match:
                                        car_name = match.group(1) if match.lastindex else match.group()
                                        break
                                if car_name != "Ù†Ø§Ù…Ø´Ø®Øµ":
                                    break
                    
                    condition = "Ù†Ø§Ù…Ø´Ø®Øµ"
                    if "ØµÙØ±" in text.lower():
                        condition = "ØµÙØ± Ú©ÛŒÙ„ÙˆÙ…ØªØ±"
                    elif "Ú©Ø§Ø±Ú©Ø±Ø¯Ù‡" in text.lower():
                        condition = "Ú©Ø§Ø±Ú©Ø±Ø¯Ù‡"
                    
                    year_match = re.search(r'(20\d{2}|13\d{2}|14\d{2})', text)
                    year = year_match.group(1) if year_match else "Ù†Ø§Ù…Ø´Ø®Øµ"
                    
                    # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ: Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±Ù‡Ø§
                    for i, price in enumerate(individual_prices):
                        display_name = car_name if len(individual_prices) == 1 else f"{car_name} (Ù‚ÛŒÙ…Øª {i+1})"
                        
                        # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ: ÙÙ‚Ø· Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù„Ø§ØªØ± Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ø®ÙˆØ¯Ø±Ùˆ
                        if display_name not in unique_cars_dict or price > unique_cars_dict[display_name]['Ù‚ÛŒÙ…Øª Ø¹Ø¯Ø¯ÛŒ']:
                            unique_cars_dict[display_name] = {
                                'Ù†Ø§Ù… Ø®ÙˆØ¯Ø±Ùˆ': display_name.strip(),
                                'ÙˆØ¶Ø¹ÛŒØª': condition,
                                'Ø³Ø§Ù„': year,
                                'Ù‚ÛŒÙ…Øª (ØªÙˆÙ…Ø§Ù†)': f"{price:,}",
                                'Ù‚ÛŒÙ…Øª Ø¹Ø¯Ø¯ÛŒ': price
                            }
                            # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ: Ù„Ø§Ú¯ ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù…ÙˆØ§Ø±Ø¯ Ø¬Ø¯ÛŒØ¯ ÛŒØ§ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´Ø¯Ù‡
                            if len(unique_cars_dict) % Z4CAR_LOG_INTERVAL == 0:
                                log_progress(f"Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯: {display_name} - {price:,} ØªÙˆÙ…Ø§Ù†")
            except:
                continue
        
        # ØªØ¨Ø¯ÛŒÙ„ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ù‡ Ù„ÛŒØ³Øª Ù†Ù‡Ø§ÛŒÛŒ
        cars_data = list(unique_cars_dict.values())
        print(f"Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(cars_data)} Ø®ÙˆØ¯Ø±ÙˆÛŒ Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ø¨Ø§ Ø±ÙˆØ´ Ø¹Ù…ÙˆÙ…ÛŒ")
        return cars_data
    
    def scrape_all_prices(self, force_update=False):
        print("Ø´Ø±ÙˆØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ø®ÙˆØ¯Ø±Ùˆ Ø§Ø² z4car.com...")
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ù‚Ø¨Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¬Ø¯Ø¯
        import os
        output_filename_xlsx = "z4car_prices.xlsx"
        if not force_update and os.path.exists(output_filename_xlsx):
            try:
                # Ø¨Ø±Ø±Ø³ÛŒ ØªØ§Ø±ÛŒØ® ÙØ§ÛŒÙ„ - Ø§Ú¯Ø± Ú©Ù…ØªØ± Ø§Ø² 12 Ø³Ø§Ø¹Øª Ø§Ø² Ø§ÛŒØ¬Ø§Ø¯ Ø¢Ù† Ú¯Ø°Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
                file_time = os.path.getmtime(output_filename_xlsx)
                current_time = time.time()
                hours_diff = (current_time - file_time) / 3600
                
                if hours_diff < 12:  # Ø§Ú¯Ø± Ú©Ù…ØªØ± Ø§Ø² 12 Ø³Ø§Ø¹Øª Ú¯Ø°Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
                    print(f"ğŸ“Š Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ù‚Ø¨Ù„ÛŒ ({hours_diff:.1f} Ø³Ø§Ø¹Øª Ù¾ÛŒØ´)")
                    df = pd.read_excel(output_filename_xlsx)
                    cars_data = df.to_dict('records')
                    print(f"âœ… {len(cars_data)} Ù‚ÛŒÙ…Øª Ø®ÙˆØ¯Ø±Ùˆ Ø§Ø² ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
                    return cars_data
                else:
                    print(f"âš ï¸ ÙØ§ÛŒÙ„ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Z4Car Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ø³Øª ({hours_diff:.1f} Ø³Ø§Ø¹Øª). Ø¯Ø± Ø­Ø§Ù„ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ...")
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ù‚Ø¨Ù„ÛŒ: {e}")
        elif force_update:
            print("ğŸ”„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Z4Car...")
        
        if not self.setup_driver():
            return []
        try:
            html_content = self.get_page_content(self.price_url)
            if not html_content:
                print("Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª ØµÙØ­Ù‡ Ø§ØµÙ„ÛŒ")
                return []
            print("ØªØ¬Ø²ÛŒÙ‡ Ùˆ ØªØ­Ù„ÛŒÙ„ Ù…Ø­ØªÙˆØ§ÛŒ ØµÙØ­Ù‡...")
            cars_data = self.extract_car_prices(html_content)
            # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø±Ø§ÛŒ Ø­Ø°Ù ØªÚ©Ø±Ø§Ø±Ù‡Ø§ Ø¨Ø§ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±
            unique_cars_dict = {}
            for car in cars_data:
                key = car['Ù†Ø§Ù… Ø®ÙˆØ¯Ø±Ùˆ']
                price = car['Ù‚ÛŒÙ…Øª Ø¹Ø¯Ø¯ÛŒ']
                if key not in unique_cars_dict or price > unique_cars_dict[key]['Ù‚ÛŒÙ…Øª Ø¹Ø¯Ø¯ÛŒ']:
                    unique_cars_dict[key] = car
                    if len(unique_cars_dict) % Z4CAR_LOG_INTERVAL == 0:
                        log_progress(f"Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯: {key} - {price:,} ØªÙˆÙ…Ø§Ù†")
            
            unique_cars = list(unique_cars_dict.values())
            print(f"Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(unique_cars)} Ø®ÙˆØ¯Ø±ÙˆÛŒ Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯")
            return unique_cars
        finally:
            if self.driver:
                self.driver.quit()
                print("WebDriver Ø¨Ø³ØªÙ‡ Ø´Ø¯")
    
    def save_to_excel(self, cars_data, filename):
        if not cars_data:
            print("Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯")
            return
        try:
            print(f"ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ {len(cars_data)} Ù‚ÛŒÙ…Øª Ø®ÙˆØ¯Ø±Ùˆ Ø¯Ø± ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„...")
            
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ DataFrame Ø¨Ø§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†ÙˆØ¹ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
            df = pd.DataFrame(cars_data)
            
            # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ: Ù…Ø±ØªØ¨â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù‚ÛŒÙ…Øª Ù†Ø²ÙˆÙ„ÛŒ
            df = df.sort_values(by='Ù‚ÛŒÙ…Øª Ø¹Ø¯Ø¯ÛŒ', ascending=False)
            
            # Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…ÙˆØªÙˆØ± openpyxl Ø¨Ø±Ø§ÛŒ Ø³Ø±Ø¹Øª Ø¨ÛŒØ´ØªØ±
            df.to_excel(filename, index=False, engine='openpyxl')
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¨Ù‡ ÙØ±Ù…Øª CSV Ø¨Ø§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ
            csv_filename = filename.replace('.xlsx', '.csv')
            df.to_csv(csv_filename, index=False, encoding='utf-8-sig')  # Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ ÙØ§Ø±Ø³ÛŒ
            
            print(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ {filename} Ùˆ {csv_filename} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
            print(f"âœ… ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡: {len(df)}")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„: {e}")
            # ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³Ø§Ø¯Ù‡â€ŒØªØ±
            try:
                print("ğŸ”„ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³Ø§Ø¯Ù‡â€ŒØªØ±...")
                pd.DataFrame(cars_data).to_excel(filename, index=False)
                print(f"âœ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³Ø§Ø¯Ù‡ Ø¯Ø± {filename} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯")
            except Exception as e2:
                print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯: {e2}")

def scrape_z4car(force_update=False):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª Ø®ÙˆØ¯Ø±Ùˆ Ø§Ø² Ø³Ø§ÛŒØª Ø²Ø¯ ÙÙˆØ± Ú©Ø§Ø± Ø¨Ø§ Ø¨Ù‡ÛŒÙ†Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø³Ø±Ø¹Øª
    
    Args:
        force_update (bool): Ø§Ú¯Ø± True Ø¨Ø§Ø´Ø¯ØŒ Ø¨Ø¯ÙˆÙ† ØªÙˆØ¬Ù‡ Ø¨Ù‡ Ø²Ù…Ø§Ù† ÙØ§ÛŒÙ„ØŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ù…Ø¬Ø¯Ø¯Ø§Ù‹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
    """
    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„ Ù‚Ø¨Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¬Ø¯Ø¯
    import os
    import time
    
    output_filename_xlsx = "z4car_prices.xlsx"
    if not force_update and os.path.exists(output_filename_xlsx):
        try:
            # Ø¨Ø±Ø±Ø³ÛŒ ØªØ§Ø±ÛŒØ® ÙØ§ÛŒÙ„ - Ø§Ú¯Ø± Ú©Ù…ØªØ± Ø§Ø² 12 Ø³Ø§Ø¹Øª Ø§Ø² Ø§ÛŒØ¬Ø§Ø¯ Ø¢Ù† Ú¯Ø°Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ØŒ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
            file_time = os.path.getmtime(output_filename_xlsx)
            current_time = time.time()
            hours_diff = (current_time - file_time) / 3600
            
            if hours_diff < 12:  # Ø§Ú¯Ø± Ú©Ù…ØªØ± Ø§Ø² 12 Ø³Ø§Ø¹Øª Ú¯Ø°Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
                print(f"ğŸš— Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ø²Ø¯ ÙÙˆØ± Ú©Ø§Ø± Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ù‚Ø¨Ù„ÛŒ ({hours_diff:.1f} Ø³Ø§Ø¹Øª Ù¾ÛŒØ´)")
                df = pd.read_excel(output_filename_xlsx)
                # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ÙØ±Ù…Øª Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
                car_data = []
                for _, row in df.iterrows():
                    car_name = row['Car Name'] if 'Car Name' in df.columns else row['Ù†Ø§Ù… Ø®ÙˆØ¯Ø±Ùˆ']
                    price = row['Price'] if 'Price' in df.columns else row['Ù‚ÛŒÙ…Øª (ØªÙˆÙ…Ø§Ù†)']
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹Ø¯Ø¯ Ù‚ÛŒÙ…Øª Ø§Ø² Ø±Ø´ØªÙ‡
                    price_number = re.sub(r'[^\d]', '', str(price))
                    if price_number:
                        price_number = int(price_number)
                    else:
                        price_number = 0
                    
                    car_data.append({
                        'Ù†Ø§Ù… Ø®ÙˆØ¯Ø±Ùˆ': car_name,
                        'ÙˆØ¶Ø¹ÛŒØª': 'Ù†Ø§Ù…Ø´Ø®Øµ',
                        'Ø³Ø§Ù„': 'Ù†Ø§Ù…Ø´Ø®Øµ',
                        'Ù‚ÛŒÙ…Øª (ØªÙˆÙ…Ø§Ù†)': f"{price_number:,}",
                        'Ù‚ÛŒÙ…Øª Ø¹Ø¯Ø¯ÛŒ': price_number
                    })
                    
                    # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù„Ø§Ú¯ Ù¾ÛŒØ´Ø±ÙØª Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ ÙˆØ¶Ø¹ÛŒØª
                    if len(car_data) % Z4CAR_LOG_INTERVAL == 0:
                        log_progress(f"Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯: {car_name} - {price_number:,} ØªÙˆÙ…Ø§Ù†")
                
                print(f"âœ… {len(car_data)} Ù‚ÛŒÙ…Øª Ø®ÙˆØ¯Ø±Ùˆ Ø§Ø² Ø²Ø¯ ÙÙˆØ± Ú©Ø§Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
                return car_data
            else:
                print(f"âš ï¸ ÙØ§ÛŒÙ„ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ø²Ø¯ ÙÙˆØ± Ú©Ø§Ø± Ù‚Ø¯ÛŒÙ…ÛŒ Ø§Ø³Øª ({hours_diff:.1f} Ø³Ø§Ø¹Øª). Ø¯Ø± Ø­Ø§Ù„ Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ...")
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙØ§ÛŒÙ„ Ù‚Ø¨Ù„ÛŒ Ø²Ø¯ ÙÙˆØ± Ú©Ø§Ø±: {e}")
    elif force_update:
        print("ğŸ”„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡â€ŒØ±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø§Ø¬Ø¨Ø§Ø±ÛŒ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ø²Ø¯ ÙÙˆØ± Ú©Ø§Ø±...")
    
    print("ğŸš— Ø´Ø±ÙˆØ¹ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø®ÙˆØ¯Ø±Ùˆ Ø§Ø² Z4Car...")
    # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ù‚Ø¨Ù„ÛŒ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´Øª ÛŒØ§ Ù‚Ø¯ÛŒÙ…ÛŒ Ø¨ÙˆØ¯ØŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¬Ø¯ÛŒØ¯ Ø§Ù†Ø¬Ø§Ù… Ø¨Ø¯Ù‡
    scraper = Z4CarScraper()
    cars_data = scraper.scrape_all_prices(force_update)
    if cars_data:
        scraper.save_to_excel(cars_data, output_filename_xlsx)
        print(f"âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {len(cars_data)} Ù‚ÛŒÙ…Øª Ø®ÙˆØ¯Ø±Ùˆ Ø§Ø² Z4Car Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")
    else:
        print("âŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Z4Car Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯")
    return cars_data

if __name__ == "__main__":
    scrape_hamrah_mechanic()
    scrape_z4car()